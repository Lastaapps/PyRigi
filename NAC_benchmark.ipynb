{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAC coloring search\n",
    "\n",
    "In this notebook we provide utils to run benchmarks and experiment with our code.\n",
    "\n",
    "In the first section we start with utility functions, in the second part we load/generate benchmark data. After we run individual benchmarks on selected graph classes with selected algorithms. The algorithms are described in that section.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir benchmarks/logs/nac\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import importlib\n",
    "from random import Random\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline as backend_inline\n",
    "from matplotlib.backends import backend_agg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import signal\n",
    "import itertools\n",
    "import base64\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nac as nac\n",
    "import nac.util\n",
    "from benchmarks import dataset\n",
    "importlib.reload(nac)\n",
    "importlib.reload(nac.util)\n",
    "importlib.reload(dataset)\n",
    "\n",
    "seed=42\n",
    "TEST=False\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\"benchmarks\", \"runs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/75898999\n",
    "from typing import Callable, TypeVar, ParamSpec\n",
    "\n",
    "P = ParamSpec(\"P\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "def copy_doc(wrapper: Callable[P, T]):\n",
    "    \"\"\"An implementation of functools.wraps.\"\"\"\n",
    "\n",
    "    def decorator(func: Callable) -> Callable[P, T]:\n",
    "        func.__doc__ = wrapper.__doc__\n",
    "        return func\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@copy_doc(plt.figure)\n",
    "def figure(num: Any = 1, *args, **kwargs) -> Figure:\n",
    "    \"\"\"Creates a figure that is independent on the global plt state\"\"\"\n",
    "    fig = Figure(*args, **kwargs)\n",
    "    def show():\n",
    "        manager = backend_agg.new_figure_manager_given_figure(num, fig)\n",
    "        display(\n",
    "            manager.canvas.figure,\n",
    "            metadata=backend_inline._fetch_figure_metadata(manager.canvas.figure),\n",
    "        )\n",
    "        manager.destroy()\n",
    "    fig.show = show\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading locally stored graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphs:\n",
    "    laman = list(dataset.load_laman_graphs())\n",
    "    laman_deg_3_plus = list(dataset.load_laman_degree_3_plus())\n",
    "    no_3_nor_4_cycles = dataset.load_no_3_nor_4_cycle_graphs()\n",
    "    sparse_graphs = dataset.generate_sparse_graphs(30, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running benchmarks\n",
    "\n",
    "Target columns are\n",
    "- `graph` - graph6 encoded graph\n",
    "- `dataset` - class of the graph, `laman`, `laman_deg_3_plus`, `no_3_nor_4_cycles`, `sparse`\n",
    "- `mode` - search mode: [`single`, `all`]\n",
    "- `vertex_no` - the number of vertices of the graph\n",
    "- `edge_no` - the number of edges of the graph\n",
    "- `triangle_components_no` - the number of triangle components of the graph\n",
    "- `monochromatic_classes_no` - the number of triangle components of the graph\n",
    "- `relabel` - relabel strategy\n",
    "- `split` - splitting strategy\n",
    "- `merging` - merging strategy\n",
    "- `subgraph_size` - the initial size of subgraphs in components\n",
    "- `nac_coloring_no` - the number of NAC colorings of the graph\n",
    "- `nac_mean_time` - the time required to find all the colorings with the given strategy in miliseconds\n",
    "- `nac_rounds` - number of rounds used to run the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS: List[str] = [\n",
    "    \"graph\",\n",
    "    \"dataset\",\n",
    "    \"vertex_no\",\n",
    "    \"edge_no\",\n",
    "    \"triangle_components_no\",\n",
    "    \"monochromatic_classes_no\",\n",
    "    \"relabel\",\n",
    "    \"split\",\n",
    "    \"merging\",\n",
    "    \"subgraph_size\",\n",
    "    \"nac_any_finished\",\n",
    "    \"nac_first_coloring_no\",\n",
    "    \"nac_first_mean_time\",\n",
    "    \"nac_first_rounds\",\n",
    "    \"nac_first_checks\",\n",
    "    \"nac_all_coloring_no\",\n",
    "    \"nac_all_mean_time\",\n",
    "    \"nac_all_rounds\",\n",
    "    \"nac_all_checks\",\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class MeasurementResult:\n",
    "    graph: str\n",
    "    dataset: str\n",
    "    vertex_no: int\n",
    "    edge_no: int\n",
    "    triangle_components_no: int\n",
    "    monochromatic_classes_no: int\n",
    "    relabel: str\n",
    "    split: str\n",
    "    merging: str\n",
    "    subgraph_size: int\n",
    "    nac_any_finished: bool\n",
    "    nac_first_coloring_no: Optional[int]\n",
    "    nac_first_mean_time: Optional[int]\n",
    "    nac_first_rounds: Optional[int]\n",
    "    nac_first_checks: Optional[int]\n",
    "    nac_all_coloring_no: Optional[int]\n",
    "    nac_all_mean_time: Optional[int]\n",
    "    nac_all_rounds: Optional[int]\n",
    "    nac_all_checks: Optional[int]\n",
    "\n",
    "    def to_list(self) -> List:\n",
    "        return [\n",
    "            self.graph,\n",
    "            self.dataset,\n",
    "            self.vertex_no,\n",
    "            self.edge_no,\n",
    "            self.triangle_components_no,\n",
    "            self.monochromatic_classes_no,\n",
    "            self.relabel,\n",
    "            self.split,\n",
    "            self.merging,\n",
    "            self.subgraph_size,\n",
    "            self.nac_any_finished,\n",
    "            self.nac_first_coloring_no,\n",
    "            self.nac_first_mean_time,\n",
    "            self.nac_first_rounds,\n",
    "            self.nac_first_checks,\n",
    "            self.nac_all_coloring_no,\n",
    "            self.nac_all_mean_time,\n",
    "            self.nac_all_rounds,\n",
    "            self.nac_all_checks,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Promissing:\n",
    "    RELABELING = [\n",
    "        \"none\",\n",
    "        \"random\",\n",
    "        # \"bfs\",\n",
    "    ]\n",
    "    SPLITTING = [\n",
    "        \"none\",\n",
    "        \"neighbors\",\n",
    "        \"neighbors_degree\",\n",
    "    ]\n",
    "    MERGING_OFFLINE = [\n",
    "        \"linear\",\n",
    "        \"log\",\n",
    "        \"score\",\n",
    "        \"shared_vertices\"\n",
    "    ]\n",
    "    MERGING_ONLINE = [\n",
    "        \"linear\",\n",
    "        \"log\",\n",
    "        \"shared_vertices\"\n",
    "    ]\n",
    "    SIZES = [6]\n",
    "\n",
    "    strategies_offline = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_OFFLINE, [4], #SIZES,\n",
    "    ))\n",
    "    strategies_online = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_ONLINE, [6], #SIZES,\n",
    "    ))\n",
    "print(f\"Offline strategies: {len(Promissing.strategies_offline)}\")\n",
    "print(f\"Online strategies:  {len(Promissing.strategies_online)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_id(graph: nx.Graph) -> str:\n",
    "    return base64.standard_b64encode(nx.graph6.to_graph6_bytes(graph, header=False).strip()).decode()\n",
    "\n",
    "def graph_from_id(id: str) -> nx.Graph:\n",
    "    return nac.util.NiceGraph(nx.graph6.from_graph6_bytes(base64.standard_b64decode(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_DataFrame(data: List[MeasurementResult] = []) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [x.to_list() for x in data],\n",
    "        columns=COLUMNS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BENCH_FILE_START = \"bench_res_v1\"\n",
    "def load_records(file_name: str | None = None, dir = OUTPUT_DIR) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the results from the last run or the run specified by `file_name` in the `dir` given.\n",
    "    \"\"\"\n",
    "    if file_name == None:\n",
    "        def filter_cond(name: str) -> bool:\n",
    "            return name.startswith(_BENCH_FILE_START) and name.endswith(\".csv\")\n",
    "        data = sorted(filter(filter_cond, os.listdir(dir)), reverse=True)\n",
    "\n",
    "        if len(data) == 0:\n",
    "            print(\"No file with results found!\")\n",
    "            return new_DataFrame()\n",
    "        file_name = data[0]\n",
    "        print(f\"Found file: {file_name}\")\n",
    "\n",
    "    path = os.path.join(dir, file_name)\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "def store_results(\n",
    "    df: pd.DataFrame,\n",
    "    file_name: str | None = None,\n",
    "    dir = OUTPUT_DIR,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Stores results in the given file\n",
    "    \"\"\"\n",
    "    if file_name is None:\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        file_name = f\"{_BENCH_FILE_START}_{current_time}.csv\"\n",
    "    path = os.path.join(dir, file_name)\n",
    "    df.to_csv(path, header=True, index=False)\n",
    "    return file_name\n",
    "\n",
    "def update_stored_data(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    df = load_records()\n",
    "    display(df)\n",
    "    df = pd.concat((df, pd.concat(dfs)))\n",
    "    df = df.drop_duplicates(\n",
    "        subset=[\"graph\", \"dataset\"],\n",
    "        keep='last',\n",
    "    )\n",
    "    store_results(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strategy(param: Tuple[str, str, str, int]) -> Tuple[str, str]:\n",
    "    relabel, split, merge, subgraph = param\n",
    "    algo_name = \"subgraphs-{}-{}-{}-smart\".format(\n",
    "        merge, split, subgraph\n",
    "    )\n",
    "    return (relabel, algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_timeout[**T, R, D](function: Callable[T, R], time_limit: int | None, default: D) -> Callable[T, R|D]:\n",
    "    if time_limit is None:\n",
    "        return function\n",
    "\n",
    "    def impl(*args: P.args, **kwargs: P.kwargs):\n",
    "        try:\n",
    "            # signals are not exact, but generally work\n",
    "            def timeout_handler(signum, frame):\n",
    "                raise TimeoutError(\"Benchmark timeout\")\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(time_limit)\n",
    "\n",
    "            res = function(*args, **kwargs)\n",
    "\n",
    "            signal.alarm(0)\n",
    "            return res\n",
    "        except TimeoutError:\n",
    "            return default\n",
    "    return impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MeasuredRecord:\n",
    "    time_sum: int\n",
    "    coloring_no: int\n",
    "    rounds: int\n",
    "    checks_performed: int\n",
    "\n",
    "    @property\n",
    "    def mean_time(self) -> int:\n",
    "        if self.rounds == 0:\n",
    "            return 0\n",
    "        return self.time_sum / self.rounds\n",
    "\n",
    "@dataclass\n",
    "class MeasuredData:\n",
    "    first: Optional[MeasuredRecord]\n",
    "    all: Optional[MeasuredRecord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nac_benchmark_core(\n",
    "    graph: nx.Graph,\n",
    "    rounds: int,\n",
    "    first_only: bool,\n",
    "    strategy: Tuple[str, str],\n",
    "    time_limit: int,\n",
    "    seed: int | None = 42,\n",
    ") -> MeasuredData:\n",
    "    \"\"\"\n",
    "    Runs benchmarks for NAC coloring search\n",
    "    Returns results grouped by relabel, split, merge and subgraph size strategies\n",
    "    \"\"\"\n",
    "\n",
    "    result = MeasuredData(None, None)\n",
    "    rand = random.Random(seed)\n",
    "\n",
    "    def find_colorings():\n",
    "        start_time = time.time()\n",
    "\n",
    "        itr = iter(\n",
    "            nac.NAC_colorings(\n",
    "                graph=graph,\n",
    "                algorithm=strategy[1],\n",
    "                relabel_strategy=strategy[0],\n",
    "                seed=rand.randint(0, 2**30),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        first_col = next(itr, None)\n",
    "        first_time = time.time()\n",
    "\n",
    "        if result.first is None:\n",
    "            result.first = MeasuredRecord(0, 0, 0, 0)\n",
    "        result.first = MeasuredRecord(\n",
    "            time_sum=result.first.time_sum + first_time - start_time,\n",
    "            coloring_no=0 if first_col is None else 1,\n",
    "            rounds=result.first.rounds + 1,\n",
    "            checks_performed=nac.NAC_check_called()[1],\n",
    "        )\n",
    "\n",
    "        if first_only:\n",
    "            return\n",
    "\n",
    "        j = 0\n",
    "        for j, coloring in enumerate(itr): pass\n",
    "        end_time = time.time()\n",
    "\n",
    "        if result.all is None:\n",
    "            result.all = MeasuredRecord(0, 0, 0, 0)\n",
    "        result.all = MeasuredRecord(\n",
    "            time_sum=result.all.time_sum + end_time - start_time,\n",
    "            coloring_no=j+1,\n",
    "            rounds=result.all.rounds + 1,\n",
    "            checks_performed=nac.NAC_check_called()[1],\n",
    "        )\n",
    "\n",
    "    def run() -> None:\n",
    "        [find_colorings() for _ in range(rounds)]\n",
    "\n",
    "    with_timeout(\n",
    "        run,\n",
    "        time_limit=time_limit*rounds,\n",
    "        default=None,\n",
    "    )()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_measurement_result(\n",
    "    graph: nx.Graph,\n",
    "    dataset_name: str,\n",
    "    trianlge_classes: int,\n",
    "    monochromatic_classes: int,\n",
    "    nac_first: Optional[MeasuredRecord],\n",
    "    nac_all: Optional[MeasuredRecord],\n",
    "    relabel_strategy: str,\n",
    "    split_strategy: str,\n",
    "    merge_strategy: str,\n",
    "    subgraph_size: int,\n",
    ") -> MeasurementResult:\n",
    "    vertex_no = nx.number_of_nodes(graph)\n",
    "    edge_no = nx.number_of_edges(graph)\n",
    "\n",
    "    nac_first_coloring_no=0\n",
    "    nac_first_mean_time=0\n",
    "    nac_first_rounds=0\n",
    "    nac_first_checks=0\n",
    "    nac_all_coloring_no=0\n",
    "    nac_all_mean_time=0\n",
    "    nac_all_rounds=0\n",
    "    nac_all_checks=0\n",
    "    nac_any_finished = (nac_first or nac_all) is not None\n",
    "\n",
    "    if nac_first is not None:\n",
    "        nac_first_coloring_no=nac_first.coloring_no\n",
    "        nac_first_mean_time=int(nac_first.mean_time*1000)\n",
    "        nac_first_rounds=nac_first.rounds\n",
    "        nac_first_checks=nac_first.checks_performed\n",
    "    if nac_all is not None:\n",
    "        nac_all_coloring_no=nac_all.coloring_no\n",
    "        nac_all_mean_time=int(nac_all.mean_time*1000)\n",
    "        nac_all_rounds=nac_all.rounds\n",
    "        nac_all_checks=nac_all.checks_performed\n",
    "\n",
    "    return MeasurementResult(\n",
    "        graph=graph_id(graph),\n",
    "        dataset=dataset_name,\n",
    "        vertex_no=vertex_no,\n",
    "        edge_no=edge_no,\n",
    "        triangle_components_no=trianlge_classes,\n",
    "        monochromatic_classes_no=monochromatic_classes,\n",
    "        relabel=relabel_strategy,\n",
    "        split=split_strategy,\n",
    "        merging=merge_strategy,\n",
    "        subgraph_size=subgraph_size,\n",
    "        nac_any_finished=nac_any_finished,\n",
    "        nac_first_coloring_no=nac_first_coloring_no,\n",
    "        nac_first_mean_time=nac_first_mean_time,\n",
    "        nac_first_rounds=nac_first_rounds,\n",
    "        nac_first_checks=nac_first_checks,\n",
    "        nac_all_coloring_no=nac_all_coloring_no,\n",
    "        nac_all_mean_time=nac_all_mean_time,\n",
    "        nac_all_rounds=nac_all_rounds,\n",
    "        nac_all_checks=nac_all_checks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def measure_for_class(\n",
    "    dataset_name: str,\n",
    "    graphs: List[nx.Graph],\n",
    "    all_max_vertex_no: int,\n",
    "    rounds:int,\n",
    "    graph_timeout: int,\n",
    ") -> pd.DataFrame:\n",
    "    dataset_name = dataset_name.replace(\" \", \"_\").lower()\n",
    "    results: List[MeasurementResult] = []\n",
    "    for graph in tqdm(graphs):\n",
    "        all_colorings = all_max_vertex_no >= graph.number_of_nodes()\n",
    "        trianlge_classes = len(nac.find_triangle_components(graph=graph, use_triangles_over_component=False)[1])\n",
    "        monochromatic_classes = len(nac.find_triangle_components(graph=graph, use_triangles_over_component=True)[1])\n",
    "\n",
    "        strategies = Promissing.strategies_offline if all_colorings else Promissing.strategies_online\n",
    "\n",
    "        for strategy in strategies:\n",
    "            search_res = nac_benchmark_core(\n",
    "                graph,\n",
    "                rounds=rounds,\n",
    "                first_only=not all_colorings,\n",
    "                strategy=create_strategy(strategy),\n",
    "                time_limit=graph_timeout,\n",
    "            )\n",
    "\n",
    "            relabel, split, merge, subgraph_size = strategy\n",
    "            res = create_measurement_result(\n",
    "                graph=graph,\n",
    "                dataset_name=dataset_name,\n",
    "                trianlge_classes=trianlge_classes,\n",
    "                monochromatic_classes=monochromatic_classes,\n",
    "                nac_first=search_res.first,\n",
    "                nac_all=search_res.all,\n",
    "                relabel_strategy=relabel,\n",
    "                split_strategy=split,\n",
    "                merge_strategy=merge,\n",
    "                subgraph_size=subgraph_size,\n",
    "            )\n",
    "            results.append(res)\n",
    "\n",
    "    df = new_DataFrame(results)\n",
    "    df = df.sort_values(by=[\"nac_all_mean_time\", \"nac_first_mean_time\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"Fail here, don't run the remaining cells automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mno = measure_for_class(\n",
    "    \"mno\",\n",
    "    # [g for g in Graphs.laman_deg_3_plus if g.number_of_nodes() == 8][:8],\n",
    "    [g for g in Graphs.sparse_graphs if g.number_of_nodes() == 13][:8],\n",
    "    all_max_vertex_no=10,\n",
    "    rounds=3,\n",
    "    graph_timeout=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df_laman = measure_for_class(\n",
    "        \"Laman\",\n",
    "        Graphs.laman,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=1,\n",
    "    )\n",
    "    update_stored_data([df_laman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    df_laman_deg_3_plus = measure_for_class(\n",
    "        \"Laman deg 3+\",\n",
    "        Graphs.laman_deg_3_plus,\n",
    "        # All with 36 strtegies, 3 rounds\n",
    "        #  8 - 1s/it\n",
    "        #  9 - 1s/it\n",
    "        # 10 - 2s/it\n",
    "        # 11 - 7s/it\n",
    "        # 12 - 15s/it -> ~20 mon. classes\n",
    "        # First coloring with 27 strategies, 3 rounds\n",
    "        # 15 - 5s/it\n",
    "        # 16 - 5s/it\n",
    "        # 17 - 90s/it\n",
    "        all_max_vertex_no=12,\n",
    "        rounds=3,\n",
    "        graph_timeout=1,\n",
    "    )\n",
    "    update_stored_data([df_laman_deg_3_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    display(pd.Series([g.number_of_nodes() for g in Graphs.no_3_nor_4_cycles]).value_counts())\n",
    "    df_no_3_nor_4_cycles = measure_for_class(\n",
    "        \"No 3 nor 4 cycles\",\n",
    "        Graphs.no_3_nor_4_cycles,\n",
    "        # 24 strategies\n",
    "        # 10 - 5 s/it\n",
    "        # 11 - 10 s/it\n",
    "        # 12 - 28 s/it\n",
    "        # 13 -\n",
    "        all_max_vertex_no=13,\n",
    "        rounds=3,\n",
    "        graph_timeout=1,\n",
    "    )\n",
    "    update_stored_data([df_no_3_nor_4_cycles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    df_sparse = measure_for_class(\n",
    "        \"Sparse\",\n",
    "        Graphs.sparse_graphs,\n",
    "        all_max_vertex_no=15,\n",
    "        rounds=3,\n",
    "        graph_timeout=3,\n",
    "    )\n",
    "    update_stored_data([df_sparse])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
