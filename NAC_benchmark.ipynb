{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAC coloring search\n",
    "\n",
    "In this notebook we provide utils to run benchmarks and experiment with our code.\n",
    "\n",
    "In the first section we start with utility functions, in the second part we load/generate benchmark data. After we run individual benchmarks on selected graph classes with selected algorithms. The algorithms are described in that section.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir benchmarks/logs/nac\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from random import Random\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline as backend_inline\n",
    "from matplotlib.backends import backend_agg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import signal\n",
    "import itertools\n",
    "import base64\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nac as nac\n",
    "import nac.util\n",
    "from benchmarks import dataset as dataset\n",
    "\n",
    "seed=42\n",
    "TEST=False\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\"benchmarks\", \"runs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/75898999\n",
    "from typing import Callable, TypeVar, ParamSpec\n",
    "\n",
    "P = ParamSpec(\"P\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "def copy_doc(wrapper: Callable[P, T]):\n",
    "    \"\"\"An implementation of functools.wraps.\"\"\"\n",
    "\n",
    "    def decorator(func: Callable) -> Callable[P, T]:\n",
    "        func.__doc__ = wrapper.__doc__\n",
    "        return func\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@copy_doc(plt.figure)\n",
    "def figure(num: Any = 1, *args, **kwargs) -> Figure:\n",
    "    \"\"\"Creates a figure that is independent on the global plt state\"\"\"\n",
    "    fig = Figure(*args, **kwargs)\n",
    "    def show():\n",
    "        manager = backend_agg.new_figure_manager_given_figure(num, fig)\n",
    "        display(\n",
    "            manager.canvas.figure,\n",
    "            metadata=backend_inline._fetch_figure_metadata(manager.canvas.figure),\n",
    "        )\n",
    "        manager.destroy()\n",
    "    fig.show = show\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading locally stored graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphs:\n",
    "    laman = list(dataset.load_laman_graphs())\n",
    "    laman_deg_3_plus = list(dataset.load_laman_degree_3_plus())\n",
    "    no_3_nor_4_cycles = dataset.load_no_3_nor_4_cycle_graphs()\n",
    "    sparse_graphs = dataset.generate_sparse_graphs(30, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running benchmarks\n",
    "\n",
    "Target columns are\n",
    "- `graph` - graph6 encoded graph\n",
    "- `dataset` - class of the graph, `laman`, `laman_deg_3_plus`, `no_3_nor_4_cycles`, `sparse`\n",
    "- `mode` - search mode: [`single`, `all`]\n",
    "- `vertex_no` - the number of vertices of the graph\n",
    "- `edge_no` - the number of edges of the graph\n",
    "- `triangle_components_no` - the number of triangle components of the graph\n",
    "- `monochromatic_classes_no` - the number of triangle components of the graph\n",
    "- `relabel` - relabel strategy\n",
    "- `split` - splitting strategy\n",
    "- `merging` - merging strategy\n",
    "- `subgraph_size` - the initial size of subgraphs in components\n",
    "- `nac_coloring_no` - the number of NAC colorings of the graph\n",
    "- `nac_mean_time` - the time required to find all the colorings with the given strategy in miliseconds\n",
    "- `nac_rounds` - number of rounds used to run the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS: List[str] =[\n",
    "    \"graph\",\n",
    "    \"dataset\",\n",
    "    \"mode\",\n",
    "    \"vertex_no\",\n",
    "    \"edge_no\",\n",
    "    \"triangle_components_no\",\n",
    "    \"monochromatic_classes_no\",\n",
    "    \"relabel\",\n",
    "    \"split\",\n",
    "    \"merging\",\n",
    "    \"subgraph_size\",\n",
    "    \"nac_coloring_no\",\n",
    "    \"nac_mean_time\",\n",
    "    \"nac_rounds\",\n",
    "]\n",
    "MODE_SINGLE = 'single'\n",
    "MODE_ALL = 'all'\n",
    "\n",
    "@dataclass\n",
    "class MeasurementResult:\n",
    "    graph: str\n",
    "    dataset: str\n",
    "    mode: str\n",
    "    vertex_no: int\n",
    "    edge_no: int\n",
    "    triangle_components_no: int\n",
    "    monochromatic_classes_no: int\n",
    "    relabel: str\n",
    "    split: str\n",
    "    merging: str\n",
    "    subgraph_size: int\n",
    "    nac_coloring_no: int\n",
    "    nac_mean_time: int\n",
    "    nac_rounds: int\n",
    "\n",
    "    def to_list(self) -> List:\n",
    "        return [\n",
    "            self.graph,\n",
    "            self.dataset,\n",
    "            self.mode,\n",
    "            self.vertex_no,\n",
    "            self.edge_no,\n",
    "            self.triangle_components_no,\n",
    "            self.monochromatic_classes_no,\n",
    "            self.relabel,\n",
    "            self.split,\n",
    "            self.merging,\n",
    "            self.subgraph_size,\n",
    "            self.nac_coloring_no,\n",
    "            self.nac_mean_time,\n",
    "            self.nac_rounds,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Promissing:\n",
    "    RELABELING = [\n",
    "        \"none\",\n",
    "        \"random\",\n",
    "        \"bfs\",\n",
    "    ]\n",
    "    SPLITTING = [\n",
    "        \"none\",\n",
    "        \"neighbors\",\n",
    "        \"neighbors_degree\",\n",
    "    ]\n",
    "    MERGING_OFFLINE = [\n",
    "        \"linear\",\n",
    "        \"log\",\n",
    "        \"score\",\n",
    "        \"shared_vertices\"\n",
    "    ]\n",
    "    MERGING_ONLINE = [\n",
    "        \"linear\",\n",
    "        \"log\",\n",
    "        \"shared_vertices\"\n",
    "    ]\n",
    "    SIZES = [6]\n",
    "\n",
    "    strategies_offline = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_OFFLINE, SIZES,\n",
    "    ))\n",
    "    strategies_online = list(itertools.product(\n",
    "        RELABELING, SPLITTING, MERGING_ONLINE, SIZES,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_id(graph: nx.Graph) -> str:\n",
    "    return base64.standard_b64encode(nx.graph6.to_graph6_bytes(graph, header=False).strip()).decode()\n",
    "\n",
    "def graph_from_id(id: str) -> nx.Graph:\n",
    "    return nac.util.NiceGraph(nx.graph6.from_graph6_bytes(base64.standard_b64decode(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_DataFrame(data: List[MeasurementResult] = []) -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        [x.to_list() for x in data],\n",
    "        columns=COLUMNS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BENCH_FILE_START = \"bench_res\"\n",
    "def load_records(file_name: str | None = None, dir = OUTPUT_DIR) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the results from the last run or the run specified by `file_name` in the `dir` given.\n",
    "    \"\"\"\n",
    "    if file_name == None:\n",
    "        def filter_cond(name: str) -> bool:\n",
    "            return name.startswith(_BENCH_FILE_START) and name.endswith(\".csv\")\n",
    "        data = sorted(filter(filter_cond, os.listdir(dir)), reverse=True)\n",
    "\n",
    "        if len(data) == 0:\n",
    "            print(\"No file with results found!\")\n",
    "            return new_DataFrame()\n",
    "        file_name = data[0]\n",
    "        print(f\"Found file: {file_name}\")\n",
    "\n",
    "    path = os.path.join(dir, file_name)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def store_results(\n",
    "    df: pd.DataFrame,\n",
    "    file_name: str | None = None,\n",
    "    dir = OUTPUT_DIR,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Stores results in the given file\n",
    "    \"\"\"\n",
    "    if file_name is None:\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        file_name = f\"{_BENCH_FILE_START}_{current_time}.csv\"\n",
    "    path = os.path.join(dir, file_name)\n",
    "    df.to_csv(path, header=True, index=False)\n",
    "    return file_name\n",
    "\n",
    "def update_stored_data(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    df = load_records()\n",
    "    display(df)\n",
    "    df = pd.concat((df, pd.concat(dfs)))\n",
    "    df = df.drop_duplicates(\n",
    "        subset=[\"graph\", \"mode\", \"dataset\"],\n",
    "        keep='last',\n",
    "    )\n",
    "    store_results(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strategy(param: Tuple[str, str, str, int]) -> Tuple[str, str]:\n",
    "    relabel, split, merge, subgraph = param\n",
    "    algo_name = \"subgraphs-{}-{}-{}-smart\".format(\n",
    "        merge, split, subgraph\n",
    "    )\n",
    "    return (relabel, algo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NAC_search_benchmark[T, R](\n",
    "    function: Callable[[T, int], R],\n",
    "    param: T,\n",
    "    rounds: int,\n",
    "    limit_sec:int|None = 3,\n",
    "    seed: int|None = 42,\n",
    ") -> Optional[Tuple[int, R]]:\n",
    "    \"\"\"\n",
    "    Runs the given function multiple times for each parameter\n",
    "    and measures the run time.\n",
    "    Returns a dictionary mapping from the param set to mean runtime in miliseconds.\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = random.randint(0, 2*32)\n",
    "    assert rounds > 0\n",
    "\n",
    "    def measure(param: T, seed: int) -> int:\n",
    "        start = time.time()\n",
    "        r = function(param, seed)\n",
    "        end = time.time()\n",
    "        return (int((end - start) * 1000), r)\n",
    "\n",
    "    try:\n",
    "        # signals are not exact, but generally work\n",
    "        if (limit_sec):\n",
    "            def timeout_handler(signum, frame):\n",
    "                raise TimeoutError(\"Benchmark timeout\")\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(limit_sec * rounds)\n",
    "\n",
    "        rand = Random(seed)\n",
    "        acu_mean, acu_other = measure(param, rand.randint(0, 2**32))\n",
    "        for _ in range(1, rounds):\n",
    "            r1, r2 = measure(param, rand.randint(0, 2**32))\n",
    "            acu_mean += r1\n",
    "        acu_mean  // rounds\n",
    "\n",
    "        if (limit_sec):\n",
    "            signal.alarm(0)\n",
    "    except TimeoutError:\n",
    "        # mean = limit_sec*1000\n",
    "        return None\n",
    "\n",
    "    return [acu_mean, acu_other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nac_benchmark_core(\n",
    "    graph: nx.Graph,\n",
    "    coloring_no_limit: int | None,\n",
    "    rounds: int,\n",
    "    strategy: Tuple[str, str],\n",
    "    seed: int | None = 42,\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Runs benchmarks for NAC coloring search\n",
    "    Returns results grouped by relabel, split, merge and subgraph size strategies\n",
    "    \"\"\"\n",
    "    if coloring_no_limit is None:\n",
    "        coloring_no_limit = 2**30\n",
    "\n",
    "    def find_colorings(strategy: Tuple[str, str], seed: int) -> int:\n",
    "        j = -1\n",
    "        for j, coloring in zip(\n",
    "            range(coloring_no_limit),\n",
    "            nac.NAC_colorings(\n",
    "                graph=graph,\n",
    "                algorithm=strategy[1],\n",
    "                relabel_strategy=strategy[0],\n",
    "                seed=seed,\n",
    "            ),\n",
    "        ): pass\n",
    "        return j\n",
    "\n",
    "    mean_time, coloring_no = run_NAC_search_benchmark(\n",
    "        function=find_colorings,\n",
    "        param=strategy,\n",
    "        rounds=rounds,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return (mean_time, coloring_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_measurement_result(\n",
    "    graph: nx.Graph,\n",
    "    dataset_name: str,\n",
    "    mode: str,\n",
    "    nac_mean_time: int,\n",
    "    nac_coloring_no: int,\n",
    "    nac_rounds: int,\n",
    "    relabel_strategy: str,\n",
    "    split_strategy: str,\n",
    "    merge_strategy: str,\n",
    "    subgraph_size: int,\n",
    ") -> MeasurementResult:\n",
    "    vertex_no = nx.number_of_nodes(graph)\n",
    "    edge_no = nx.number_of_edges(graph)\n",
    "    trianlge_classes = len(nac.find_triangle_components(graph=graph, use_triangles_over_component=False)[1])\n",
    "    monochromatic_classes = len(nac.find_triangle_components(graph=graph, use_triangles_over_component=True)[1])\n",
    "    return MeasurementResult(\n",
    "        graph=graph_id(graph),\n",
    "        dataset=dataset_name,\n",
    "        mode=mode,\n",
    "        vertex_no=vertex_no,\n",
    "        edge_no=edge_no,\n",
    "        triangle_components_no=trianlge_classes,\n",
    "        monochromatic_classes_no=monochromatic_classes,\n",
    "        nac_coloring_no=nac_coloring_no,\n",
    "        nac_mean_time=nac_mean_time,\n",
    "        nac_rounds=nac_rounds,\n",
    "        relabel=relabel_strategy,\n",
    "        split=split_strategy,\n",
    "        merging=merge_strategy,\n",
    "        subgraph_size=subgraph_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def measure_for_class(\n",
    "    dataset_name: str,\n",
    "    graphs: List[nx.Graph],\n",
    "    coloring_all_range: Tuple[int, int],\n",
    "    coloring_single_range: Tuple[int, int],\n",
    "    rounds:int,\n",
    ") -> pd.DataFrame:\n",
    "    dataset_name = dataset_name.replace(\" \", \"_\").lower()\n",
    "    results: List[MeasurementResult] = []\n",
    "    for graph in tqdm(graphs):\n",
    "        for mode_name, strategies, coloring_range, coloring_limit in zip(\n",
    "            (MODE_ALL, MODE_SINGLE),\n",
    "            (Promissing.strategies_offline, Promissing.strategies_online),\n",
    "            (coloring_all_range, coloring_single_range),\n",
    "            (None, 1),\n",
    "        ):\n",
    "            n = graph.number_of_nodes()\n",
    "            if n < coloring_range[0] or n > coloring_range[1]:\n",
    "                continue\n",
    "            for strategy in strategies:\n",
    "                mean_time, coloring_no = nac_benchmark_core(\n",
    "                    graph,\n",
    "                    coloring_no_limit=coloring_limit,\n",
    "                    rounds=rounds,\n",
    "                    strategy=create_strategy(strategy),\n",
    "                )\n",
    "\n",
    "                relabel, split, merge, subgraph_size = strategy\n",
    "                res = create_measurement_result(\n",
    "                    graph=graph,\n",
    "                    dataset_name=dataset_name,\n",
    "                    mode=mode_name,\n",
    "                    nac_mean_time=mean_time,\n",
    "                    nac_rounds=rounds,\n",
    "                    nac_coloring_no=coloring_no,\n",
    "                    relabel_strategy=relabel,\n",
    "                    split_strategy=split,\n",
    "                    merge_strategy=merge,\n",
    "                    subgraph_size=subgraph_size,\n",
    "                )\n",
    "                results.append(res)\n",
    "\n",
    "    df = new_DataFrame(results)\n",
    "    df = df.sort_values(by=\"nac_mean_time\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laman = measure_for_class(\n",
    "    \"Laman\",\n",
    "    Graphs.laman,\n",
    "    (8, 15),\n",
    "    (8, 100),\n",
    "    rounds=3,\n",
    ")\n",
    "update_stored_data([df_laman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laman_deg_3_plus = measure_for_class(\n",
    "    \"Laman deg 3+\",\n",
    "    Graphs.laman_deg_3_plus,\n",
    "    (8, 15),\n",
    "    (8, 100),\n",
    "    rounds=3\n",
    ")\n",
    "update_stored_data([df_laman_deg_3_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_3_nor_4_cycles = measure_for_class(\n",
    "    \"No 3 nor 4 cycles\",\n",
    "    Graphs.no_3_nor_4_cycles,\n",
    "    (8, 15),\n",
    "    (8, 100),\n",
    "    rounds=3\n",
    ")\n",
    "update_stored_data([df_no_3_nor_4_cycles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sparse = measure_for_class(\n",
    "    \"Sparse\",\n",
    "    Graphs.sparse_graphs,\n",
    "    (8, 15),\n",
    "    (8, 100),\n",
    "    rounds=3\n",
    ")\n",
    "update_stored_data([df_sparse])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
